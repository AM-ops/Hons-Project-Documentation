% Chapter 3

\chapter{Artefact Design \& Development} % Main chapter title
\label{Chapter3} % For referencing the chapter elsewhere, use \ref{Chapter3}
\section{Description of Artefact}
The nature of the research that is conducted in this study leads to a contrasting artefact that is delivered. The artefact is a culmination of image processing, programming, GIS data handling, and problem solving. This is made obvious as this chapter progresses further. In essence the artefact is the steps and procedures followed to come up with the final CA model.
\section{Life Cycle Methodology}
\label{sec:lcm}
For the entire development of the Artefact a combination of three methodologies was utilised. These included:
\begin{itemize}
\item Waterfall
\item Agile
\item Scrum
\end{itemize}
The rationale for utilising this combination was due to the following factors:
\begin{itemize}
\item The emphasis on self-management for the design and development of the Artefact.
\item Incremental changes made in short iterations.
\item Segmenting problems into workable pieces and thereafter completing them in an effective manner.
\item Analysing and recording each stage of the research progress and evaluating the progress to prevent backsliding.
\item Iteratively solving smaller issues and problems as they arise.
\end{itemize}
\section{Design Science Schema for Research Study}
According to Gregor \& Hevner, 2013 there are seven sections involved in tackling a Research study. They are listed as follows:\cite{dssteps}
\begin{enumerate}
\item Introduction
\item Literature Review
\item Method
\item Artifact Description
\item Evaluation
\item Discussion
\item Conclusions
\end{enumerate}
In conjunction with the methodologies discussed in Section \ref{sec:lcm} this research study will incorporate the Design Science Schema as follows:
\begin{itemize}
\item Chapter \ref{Chapter1} of this research study will fall under Step 1.
\item Chapter \ref{Chapter2} of this research study will fall under Step 2.
\item Chapter \ref{Chapter3} of this research study will fall under Steps 3, 4 and 5.
\item Chapter \ref{Chapter4} of this research study will fall under Step 6.
\item Chapter \ref{Chapter5} of this research study will fall under the last Step 7.
\end{itemize}
\section{Data Acquisition}
\subsection{Closed Sourced Data}
After the Literature Review was conducted the search for data began. A company by the name of GeoTerraImage (Pty) Ltd\footnote{\url{https://geoterraimage.com/}} which is located in Pretoria, South Africa was contacted and a data request was filed. The GIS data received was for an Informal settlement named \textit{"Melusi"}. The author is grateful for the data provided. The dataset received contained three main points of interest to this research:
\begin{itemize}
\item The outline or boundary of the \textit{"Melusi"} area.
\item The Building Based Land Usage in the form of housing for the year 2010 for \textit{Melusi}.
\item The Building Based Land Usage in the form of housing for the year 2020 for \textit{Melusi}.
\end{itemize}
\subsection{Open Sourced Data}
\label{sec:open}
To assist with the CA modelling additional data was needed. The following two websites  were utilised:
\begin{itemize}
\item The Humanitarian Data Exchange\footnote{\url{https://data.humdata.org/}}
\item The South African Department of Water and Sanitation\footnote{\url{https://www.dwa.gov.za/}}
\end{itemize}
From the above mentioned websites the following GIS data was acquired:
\begin{itemize}
\item All the medium-scale river coverage in South Africa.\footnote{\url{https://www.dws.gov.za/iwqs/gis_data/river/rivs500k.aspx}} This dataset was in the \texttt{.SHP} format.
\item All the Road networks in South Africa provided by HOTOSM (Humanitarian OpenStreetMap Team) and available for download by HDX (The Humanitarian Data Exchange).\footnote{\url{https://data.humdata.org/dataset/hotosm_zaf_roads}} This dataset was in the \texttt{.SHP} format.
\item High Resolution Population Density Maps \& Demographic Estimates in South Africa in the year 2019 which was once again made available for download by HDX.\footnote{\url{https://data.humdata.org/dataset/cbfc4206-35c8-42d4-a096-b2dd0aec983d}} This dataset was in the \texttt{.TIF} format.
\end{itemize}
\section{Data Exploration and Preprocessing}
\subsection{Usage of Geographic Information Systems}
\label{sec:GIS}
The use of Geographic Information Systems (GIS) was not greatly successful in this research. The factors limiting the usage were; the lack of packages, libraries, add-ons, or plug-ins that function "out-of-the-box", the ones that do work tend to fulfill niched application or specific problems.

Additional issues encountered were as follows:
\begin{itemize}
\item Incompatibility of Operating Systems.
\item GIS data formats were incompatible.
\item Researchers publising their Masters or Doctorates research made custom tools that were specific to their research.
\end{itemize}
The following GIS tools were utilised in the early stages of the research:
\begin{itemize}
\item ESRI's ArcGIS (Proprietary commercial software).\footnote{\url{https://www.esri.com/en-us/home}}
\item QGIS (Open-source software).\footnote{\url{https://qgis.org/en/site/}}
\end{itemize}

The following packages, libraries, add-ons, or plug-ins were also utilised in the early stages of the research:
\begin{itemize}
\item MOLUSCE - A plugin for QGIS for Land Use Change Evaluation.\footnote{\url{https://wiki.gis-lab.info/w/Landscape_change_analysis_with_MOLUSCE_-_methods_and_algorithms}}
\item TerraME - A Multiparadigm Modeling Toolkit.\footnote{\url{http://www.terrame.org/doku.php}}
\item GeoSOS (Geographic Simulation \& Optimization System) - A standalone program or as an add-on for ArcGIS.\footnote{\url{https://www.geosimulation.cn/GeoSOS/}}
\end{itemize}
These endeavours were also unfruitful with the reasons being the same as mentioned above.

It should be noted that the above packages do have CA modelling capabilities but were limited. The author embarked on creating his own model.

Lastly, another key hurdle was the availability of some tools which required the use of programming languages that were out of the scope of this author's skill set.

The dataset that were acquired up until this point had to analysed, therefore the next logical step was to load the GIS data into the GIS software to provide a quick overview.
\subsection{Handling of GIS Data in GIS Software}
The datasets were loaded first into ArcGIS and thereafter into QGIS. The figures below demonstrate the output achieved.
\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{Figures/Chapter3/ArcGIS}
\caption{Output of the datasets in ArcGIS}
\label{fig:Arc}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{Figures/Chapter3/QGIS}
\caption{Output of the datasets in QGIS}
\label{fig:Q}
\end{figure}
In the Figure \ref{fig:Arc} where ArcGIS is shown, the dark green colour represent Building Based Land Usage in the year 2020, however the Land Usage for the year 2010 was blended inside the bigger Building Based Land Usage of 2020. The lighter green colour represents the roads network in the year 2019.

In the next Figure \ref{fig:Q} where QGIS is shown, the black colour represents the population dataset, the light green colour represents the boundary of the \textit{Melusi} area. The blue colour represents the Building Based Land Usage for the year 2010, and the purple colour is the Building Based Land Usage for the year 2020. Lastly, the light pink colour represents the roads network in the year 2019.

At this juncture the dataset for the medium-scale river coverage was dropped from the research as both the GIS software indicated that there was not any rivers close by  in the area.

As was mentioned in Section \ref{sec:GIS} this was the limit of the GIS software usage in this research. The next approach was to utilise the Python programming language as well as its vast array of libraries.
\subsection{Handling of GIS Data with Python}
The primary approach used with Python was the use of Python Notebooks. These were run in two different environments:
\begin{itemize}
\item Locally using Jupyter Notebook.\footnote{\url{https://jupyter.org/}}
\item On the cloud using Google Colaboratory.\footnote{\url{https://research.google.com/colaboratory/}}
\end{itemize}
Jupyter Notebook utilises the local resources an individual has on a computer to run Python code.

Google Colab is an example of Platform as a Service (PaaS), and Infrastructure as a Service (IaaS) combined into one service.

PaaS is a cloud service model which supports application development in the cloud using languages and other tools. IaaS on the other hand is cloud service model which offers network components, storage, and processing in the cloud.\cite{pf} These service models do not require users to have powerful computing components as it is "outsourced" to these vendors such as Google.

Therefore, the only requirement for Google Colab is to utilise a modern browser that is capable of opening the Colab website to run Python code.
\\\\
The Geopandas\footnote{\url{https://geopandas.org/}} and the Matplotlib\footnote{\url{https://matplotlib.org/}} libraries were utilised to load the datasets and carry out elementary visual analysis. Additionally, the library called Folium\footnote{\url{https://python-visualization.github.io/folium/}} was utised to create an interactive map to demonstrate the boundaries of \textit{Melusi} in repect to other surrounding regions.

The first dataset to be loaded was the \textit{Melusi} dataset which had the \texttt{.SHP} files. This was done using the Geopandas \texttt{read\_file} method.\footnote{\url{https://geopandas.org/docs/reference/api/geopandas.read_file.html}}\\\\
From the Folium library the \texttt{map} method\footnote{\url{https://python-visualization.github.io/folium/modules.html\#module-folium.map}} was utilised after the coordinates were extracted from the data loaded into Geopandas and visualisations were made using Matplotlib. The \texttt{pyplot.plot} method\footnote{\url{https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html\#matplotlib.pyplot.plot}} was used for this step.

Below are a few figures that were created in this process. The coordinates of this region can also be seen in the figures above.
For more information on these steps involved, the Appendix \ref{AppendixC} has more details.
\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{Figures/Chapter3/MelusiArea}
\caption{The boundary of the \textit{Melusi} area}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{Figures/Chapter3/Melusi2010}
\caption{The Building Based Land Usage of the \textit{Melusi} area in 2010}
\label{fig:mel2010}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{Figures/Chapter3/Melusi2020}
\caption{The Building Based Land Usage of the \textit{Melusi} area in 2020}
\label{fig:mel2020}
\end{figure}
Once the coordinates were acquired the Folium interactive map was created of the \textit{Melusi} area. This is shown at the endof this Chapter in Figures \ref{fig:fol} and \ref{fig:fol2}. The surrounding suburbs and regions can also be seen. The webpages for these can be accessed here\footnote{\url{https://github.com/AM-ops/Hons-Project-Documentation/blob/main/Hons-Project-Documentation-Final/Web/melusi_area.html}}$^{,}$\footnote{\url{https://github.com/AM-ops/Hons-Project-Documentation/blob/main/Hons-Project-Documentation-Final/Web/melusi_area2.html}}
The file can be downloaded and thereafter viewed interactively in a browser.

The Building Based Land Usage for 2010 and 2020 can be seen in Figures \ref{fig:mel2010} and \ref{fig:mel2020}

After the above \textit{Melusi} area datasets were explored the next two variables needed to be explored. These were the road networks and the population datasets.

The road networks dataset as was mentioned in Section \ref{sec:open} is in the \texttt{.SHP} format, therefore once again the Geopandas \texttt{read\_file} method was employed to read the data. However the population dataset was in the \texttt{.TIF} format therefore another library Rioxarray had to be utilised.\footnote{\url{https://corteva.github.io/rioxarray/stable/rioxarray.html}} The method from this library is to read the file is \texttt{open\_rasterio}.

Data that is loaded using Geopandas is stored in \texttt{GeoDataFrames} whereas the data loaded using Rioxarray is stored in \texttt{DataArrays}. Each of these data structures have different methods and properties that allow for the manipulation of the data. This is demonstrated below.

In the next procedure the following has to be kept in mind; the aforementioned two datasets contain data for the entirety of South Africa, therefore they have to be limited to just the \textit{Melusi} area. To accomplish this firstly, the \textit{Melusi} area's boundary was extracted using the \texttt{GeoSeries.total\_bounds} property\footnote{\url{https://geopandas.readthedocs.io/en/latest/docs/reference/api/geopandas.GeoSeries.total_bounds.html}} provided by Geopandas.

Thereafter, this boundary limit was applied to the data structures mentioned earlier. This is done through the \texttt{cx} property\footnote{\url{https://geopandas.org/docs/reference/api/geopandas.GeoDataFrame.cx.html}} from Geopandas and was applied to the road networks \texttt{GeoDataFrame}. The \texttt{rio.clip\_box} method\footnote{\url{https://corteva.github.io/rioxarray/stable/_modules/rioxarray/raster_array.html\#RasterArray.clip_box}} from Rioxarray was applied to the population \texttt{DataArray}.

Matplotlib was once again employed for plotting purposes. The resulting images for the population and road networks datasets is shown in Figures \ref{fig:popgraph} and \ref{fig:roadgraph}.
\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{Figures/Chapter3/Roads2019}
\caption{The Road Networks in the \textit{Melusi} area as of 2019}
\label{fig:roadgraph}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{Figures/Chapter3/Population2019}
\caption{The Population Density of the \textit{Melusi} area as of 2019}
\label{fig:popgraph}
\end{figure}
%ax = roads.plot(color="black", figsize=(7,5))
%ax.set\_axis\_off()
%ax.set(xlim=(xmin, xmax), ylim=(ymin, ymax))
%ax.autoscale\_view(scalex=False, scaley=False)
%ax.autoscale(enable=False)
%ax.autoscale(enable=False)
%plt.savefig("roads-nox.jpg",dpi=1200)
The next process involved exporting or saving high quality images of all the figures shown above namely; Figures \ref{fig:mel2010}, \ref{fig:mel2020}, \ref{fig:roadgraph}, and \ref{fig:popgraph}. A 2-Dimensional grid or lattice is needed for a CA model hence the need to export the images. An image is in essence a 2-Dimensional grid whereby the width and height is predefined and any pixel in the image can be referenced using a 2-Dimensional co-ordinate system.

The pixel density (known as Dots Per Inch or DPI)\cite{dpi} was set to 1,200 and the Matplotlib library's \texttt{pyplot.savefig}\footnote{\url{https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html}} method was called to save all the images. Additionally, the axes were set to be turned off\footnote{\url{https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.axes.Axes.set_axis_off.html}} and, the autoscale\footnote{\url{https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.autoscale.html}} for figures was set to \texttt{False}.\\\\
Before the images were saved a few key aspects had to be verified. The first was making sure the Coordinate Reference System (CRS) was the same for all the datasets involved. The approach for \texttt{GeoDataFrames} is to call the \texttt{crs} property\footnote{\url{https://geopandas.org/docs/reference/api/geopandas.GeoDataFrame.crs.html}} and for the \texttt{DataArrays} the \texttt{rio.crs} accessor\footnote{\url{https://corteva.github.io/rioxarray/stable/getting_started/crs_management.html}} can be accessed.

The CRS for all the datasets was \textit{EPSG 4326}, therefore the process of saving the images was done immediately without the need for the CRS for any dataset to be changed.
\subsection{Image Processing with OpenCV}
\label{sec:imgproc}
After the images above were saved and analysed the following final dimensions were achieved, thanks to the high DPI;
\begin{itemize}
\item Width: 7,200 px
\item Height: 4,800 px
\end{itemize}
To assist in the CA modelling (discussed further down) and to simplify the process, one of the approached that can be taken is to scale the images (also known as resizing). Another approach is to grayscale the images. Both of these approaches were applied. The rationale behind using these approaches is as follows; A trade off can be made between computational time in modelling with the data loss in an image.\cite{impact} Additionally, the norm in Image Processing Modelling is to utilise Convolutional Neural Networks, this will not be the approach taken in this research.\cite{cnn}

With regards to grayscaling, and fields such as image recognition the method or type of algorithms utilised to grayscale color images does impact performance.\cite{gray} However in this research those finer details are not in the project scope, hence a basic grayscale operation was performed for all of the following images:
\begin{itemize}
\item Building Based Land Usage of the \textit{Melusi} area in 2010.
\item Building Based Land Usage of the \textit{Melusi} area in 2020.
\item Road networks of the \textit{Melusi} area in 2019.
\item Population Density of the \textit{Melusi} area in 2019.
\end{itemize}

The grayscale operation was carried out using the Python version of the OpenCV library\footnote{\url{https://docs.opencv.org/4.x/}}. The conversion from a RGB image to grayscale is done with the \texttt{cvtColor} method\footnote{\url{https://docs.opencv.org/3.4.15/de/d25/imgproc_color_conversions.html}}

The grayscale formula from OpenCV's Documentation is as follows:
\begin{center}
$\text{RGB[A] to Gray:} \quad Y \leftarrow 0.299 \cdot R + 0.587 \cdot G + 0.114 \cdot B$
\end{center}
This formula simplified means the Red value of a pixel is multiplied with 0.299, the Green value of the pixel is multiplied with 0.587, and lastly the Blue value of a pixel is multiplied with 0.114. These new three values are summed up to give one value for the pixel in grayscale.

The first three images listed above do not differ greatly visually as they are mainly white and black to start of with. Therefore, the Population Density image is ideal to demonstrate the output of the grayscale operation. Below in Figure \ref{fig:popogray} the output is visualised.
\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{Figures/Chapter3/popgray}
\caption{The grayscale image from the Population Density data}
\label{fig:popogray}
\end{figure}
Additionally, the process of scaling the images utilised the \texttt{resize} method\footnote{\url{https://docs.opencv.org/3.4.15/da/d54/group\_\_imgproc\_\_transform.html\#ga47a974309e9102f5f08231edc7e7529d}} which was called. The scale factor was $\frac{1}{3}$. This scale factor was chosen to prevent excess data. At this stage the Data Preprocessing is complete and the only aspect remaining is to to save the images after being processed. For this the \texttt{imwrite} function\footnote{\url{https://docs.opencv.org/4.x/d4/da8/group__imgcodecs.html\#gabbc7ef1aa2edfaa87772f1202d67e0ce}} from OpenCV was called for each of the four final images.

Thereafter, the Online Photo Editor, Photopea\footnote{\url{https://www.photopea.com/}} was employed to trim some of the edges of the images. The resulting dimensions of the images were as follows:
\begin{itemize}
\item Width: 2,160 px
\item Height: 830 px
\end{itemize}
These resulting dimensions were ideal for the next process which involved creating the CA model.
\section{Cellular Automata Modelling}
\subsection{Preliminary Discussion}
To begin the process of creating the CA model, the first step involves reading the final images created from the steps in Section \ref{sec:imgproc}. This once again requires the use of OpenCV. The function employed is the \texttt{imread} function\footnote{\url{https://docs.opencv.org/4.x/d4/da8/group__imgcodecs.html\#ga288b8b3da0892bd651fce07b3bbd3a56}}.

Once the images are read into variables the grayscale function has to be applied again. This is due to the nature of the \texttt{imwrite} function which saves images in the RGB format. This is also true for images that where grayscaled before and saved.

The \texttt{imread} function returns a \texttt{ndarray} also know as a NumPy N-Dimensional Array. In the case of Images the \texttt{ndarray} is a 2-Dimensional Array. Using NumPy's Indexing\footnote{\url{https://numpy.org/doc/stable/reference/arrays.indexing.html\#arrays-indexing}} (Slicing) capabilities one can effortlessly access any value in the \texttt{ndarray}. The images needed for the modelling process are read into separate variables and the next procedures can be carried out.
\\\\
At this juncture the 2-Dimensional grids for the CA model are ready in the form of \texttt{ndarrays}. The images which are read into \texttt{ndarrays} are ready for a custom thresholding. As was expanded in Section \ref{sec:col}, thresholding is an additional approach that makes the process of defining rules for the CA modelling slightly more elementary. The two \texttt{ndarrays} that are put through the thresholding process are:
\begin{itemize}
\item The Population Density
\item The Road Networks
\end{itemize}
For the Population Density array all the unique values were extracted using the NumPy \texttt{unique} Set routine. The Table \ref{table:uniq} below shows the output of these values.
\begin{table}[H]
\caption{Unique values found in the population \texttt{ndarray}}
\label{table:uniq}
\centering
\begin{tabular}{@{}l@{}}
\toprule
\multicolumn{1}{c}{Unique Values} \\ \midrule
0.5483527804562259                \\
1.9322995070209252                \\
2.494171667535703                 \\
2.5802248275941975                \\
2.928383276590716                 \\
3.843662634917949                 \\
3.9742969374931736                \\
4.0719211311237515                \\
5.236094447939968                 \\
5.558666899272438                 \\
NaN                               \\ \bottomrule
\end{tabular}
\end{table}
From this table the function \texttt{replaceWithPopulationDensity} was created. The details of this can be found in Appendix \ref{AppendixC}.

For the Roads a simpler threshold function was created which was called \texttt{replaceRoadsForCalc}. The basic principle for this function is to replace all pixels in the array with a 1 if it is black (Meaning a road is present at that pixel) or white otherwise (no road present). The details can once again be found in Appendix \ref{AppendixC}.

These custom functions that were created utilised the NumPy \texttt{vectorize} function\footnote{\url{https://numpy.org/doc/stable/reference/generated/numpy.vectorize.html}} to be applied to the entire arrays. The rationale for using \texttt{vectorize} is increased computational speed in carrying out the functions.

Another custom function that utilses \texttt{vectorize} is the \texttt{replaceBWForCalculations}. This function is exactly the same as the \texttt{replaceRoadsForCalc}, however it is used in the course of the CA model's simulation runtime. As the name suggests it replaces Black and White pixels with 1s and 0s in the Building Based Land Usage array.

The Roads array and the Population array which are vectorized, from here on will be labelled as \textit{variable arrays}. The two Building Based Land Usage arrays, which are not yet vectorized will be labelled as \textit{State arrays} due to them having states in the CA model simulation.

At this point all the four arrays which are synonymous with the four images saved in Section \ref{sec:imgproc} should be kept in mind as a 2-Dimensional array or grid on which a CA model can be created and simulated. The Figure \ref{fig:gridlayers} shows a diagrammatical visualisation of three identical (with regards to width and height) 2-Dimensional data arrays. The figure demonstrates that referencing a specific block or cell within these grid would be the same in any of them.
\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{Figures/Chapter3/gridlayers}
\caption{Multiple Identical 2D Arrays visualised}
\label{fig:gridlayers}
\end{figure}
The next logical step is to formulate rules for the CA Model. However before this can be conducted, the Rule of Adjacency from Section \ref{sec:LitCA} can be discussed further. The reason for this is to manage any and all edge cases that may arise while creating the rules for the CA model.

Additionally, the method of referencing blocks based on location should be uniform, therefore below in Figure \ref{fig:labs} the naming conventions for this research are specified. These are also the labels which are used in the code located in Appendix \ref{AppendixC}. 
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{Figures/Chapter3/labels}
\caption{Naming conventions for neighbours}
\label{fig:labs}
\end{figure}
The avant-garde approach which in turn is also intuitive to solve the issues of edge cases is to visualise two separate 2-Dimensional arrays. The first is of size $3 \times 3$ (labelled as $A$), and the the other is $n \times n$ (labelled as $B$) where $n$ is of arbitrary value. Thereafter, assign the center block of grid $A$ as the \textit{Current} or \textit{Active} cell, and any of the other neighbouring cells as the edge case to be tested. Place the \textit{Current} cell on top of grid $B$ and align it with the top-left cell of grid $B$. Keeping the grid $B$ static begin to move grid $A$ towards the right-hand side of the grid $B$. Take note of the cells where the current edge case being tested fails. In other words, the edge case's cell lies outside of the grid $B$. All the edge cases can therefore be managed in any grid of size ($n \times n$) if the procedure is followed correctly. In the Figures \ref{fig:e1}, \ref{fig:e2}, \ref{fig:e3}, and \ref{fig:e4} this avant-garde process is demonstrated visually. The colours in the pictures are defined below:
\begin{itemize}
\item Green - \textit{Current} or \textit{Active} Cell
\item Grey - Neighbours of \textit{Current} Cell not being tested at the moment
\item Red - Edge case being tested.
\item Blue - Locations where edge case (in Red) passes
\item White - Locations where edge case (in Red) fails 
\end{itemize}

\begin{figure}[H]
\centering
\begin{subfigure}{.4\textwidth}
  \centering
  \includegraphics[width=.5\linewidth]{Figures/Chapter3/botleft}
  \caption{Bottom Left Cell}
\end{subfigure}%
\begin{subfigure}{.4\textwidth}
  \centering
  \includegraphics[width=.5\linewidth]{Figures/Chapter3/botright}
  \caption{Bottom Right Cell}
\end{subfigure}
\caption{Edge cases for Bottom Diagonal Cells}
\begin{center}
Source: Own Creation (2021)
\end{center}
\label{fig:e1}
\end{figure}

\begin{figure}[H]
\centering
\begin{subfigure}{.4\textwidth}
  \centering
  \includegraphics[width=.5\linewidth]{Figures/Chapter3/topright}
  \caption{Top Right Cell}
\end{subfigure}%
\begin{subfigure}{.4\textwidth}
  \centering
  \includegraphics[width=.5\linewidth]{Figures/Chapter3/topleft}
  \caption{Top Left Cell}
\end{subfigure}
\caption{Edge cases for Top Diagonal Cells}
\begin{center}
Source: Own Creation (2021)
\end{center}
\label{fig:e2}
\end{figure}

\begin{figure}[H]
\centering
\begin{subfigure}{.4\textwidth}
  \centering
  \includegraphics[width=.5\linewidth]{Figures/Chapter3/topmid}
  \caption{Top Middle Cell}
\end{subfigure}%
\begin{subfigure}{.4\textwidth}
  \centering
  \includegraphics[width=.5\linewidth]{Figures/Chapter3/botmid}
  \caption{Bottom Middle Cell}
\end{subfigure}
\caption{Edge cases for Middle Column Cells}
\begin{center}
Source: Own Creation (2021)
\end{center}
\label{fig:e3}
\end{figure}

\begin{figure}[H]
\centering
\begin{subfigure}{.4\textwidth}
  \centering
  \includegraphics[width=.5\linewidth]{Figures/Chapter3/midleft}
  \caption{Middle Left Cell}
\end{subfigure}%
\begin{subfigure}{.4\textwidth}
  \centering
  \includegraphics[width=.5\linewidth]{Figures/Chapter3/midright}
  \caption{Middle Right Cell}
\end{subfigure}
\caption{Edge cases for Middle Row Cells}
\begin{center}
Source: Own Creation (2021)
\end{center}
\label{fig:e4}
\end{figure}
The rationale behind this lengthy and detail process is due to the following reasons:
\begin{itemize}
\item The CA model must not throw any errors while it iterates through the grid
\item The next step which involves formulating growth rules for the CA model contains the process of splitting the original 3 arrays into $10 \times 10$ sized smaller arrays. This translates to a $10 \times 10$ pixel block in the final images.
\end{itemize}
\subsection{Formulation of Rules}
Referring back to the information provided in Section \ref{sec:imgproc}, the reasoning for having images in the dimensions of 2,160 px by 830 px is clear. These images which are now called \textit{variable arrays} when they are assigned to variables (after being read)  will have the same 2-Dimensional size, hence the step of splitting the variable arrays into smaller subsets is simplified without being wary of outlying values. The grid size for the CA model is therefore in the dimensions of $2,160 \times 830$ elements. The individual cells dimensions in this grid are $10 \times 10$, therefore the total cells present is:
\begin{center}
$216 \times 83 = 17,928$
\end{center}
The concept of Pooling was discussed in Section \ref{sec:col}, the different rules that can be applied to down-size inputs was also touched upon. The Figure \ref{fig:pool} demonstrated the Max rule which returns the maximum value from a given set, however for this research study the summing and averaging approach is employed. The detailed procedure is discussed below.

The Cumulative Sum of all individual cells in the variable arrays is taken. This means a total of 35,856 Cumulative Sums are carried out ($17,928 + 17,928 = 35,856$ for the two variable arrays). To calculate this sum the NumPy \texttt{cumsum} routine\footnote{\url{https://numpy.org/doc/stable/reference/generated/numpy.cumsum.html}} was called. Thereafter each of the Cumulative Sums is divided by $100$ to get the Average Cumulative Sum. This is because each cell in the variable arrays has $10 \times 10 = 100$ values.

The Figure \ref{fig:cumsumpool} below demonstrates an example of a Cumulative Sum Pool Operation which is carried out for each of the cells in the variable arrays. This operation sums all the values found in a given cell. The averages of each these sums (35,856 in total) is easily calculated thereafter.
\begin{figure}
\centering
\includegraphics[scale=0.7]{Figures/Chapter3/sumpool}
\caption{An example of a \textit{Cumulative Sum Pool Operation}}
\label{fig:cumsumpool}
\end{figure}
After the averages of the Cumulative Sums is carried out the frequency of said averages is visualised to analyse the spread of the occurring values. This is then used to formulate conditional rules for the CA model. The Figures \ref{fig:cumsumpop} and \ref{fig:cumsumroad} below display the results of the visualisations.
\begin{figure}[H]
\centering
\includegraphics[scale=0.7]{Figures/Chapter3/populationSum}
\caption{Frequency of Averages of the Cumulative Sums in the Population variable array}
\label{fig:cumsumpop}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[scale=0.7]{Figures/Chapter3/roadsSum}
\caption{Frequency of Averages of the Cumulative Sums in the Roads variable array}
\label{fig:cumsumroad}
\end{figure}

\begin{figure}[H]
\centering
%\includegraphics[width=20cm,height=15cm,keepaspectratio]{Figures/Chapter3/Folium}
\includegraphics[scale=0.30,angle=90]{Figures/Chapter3/Folium}
\caption{Interactive map of the \textit{Melusi} area}
\label{fig:fol}
\end{figure}
\begin{center}
Source: Own Creation (2021)
\end{center}
\pagebreak
\begin{figure}[H]
\centering
\includegraphics[scale=0.5,angle=90]{Figures/Chapter3/Folium2}
\caption{Another Interactive map of the \textit{Melusi} area}
\label{fig:fol2}
\end{figure}
\begin{center}
Source: Own Creation (2021)
\end{center}